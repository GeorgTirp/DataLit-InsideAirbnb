{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10380336,"sourceType":"datasetVersion","datasetId":6430266}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nilsklute/kaggle-airbnb-preprocessing?scriptVersionId=217170820\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **AirBnB Notebook**","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2025-01-10T11:01:05.068427Z","iopub.execute_input":"2025-01-10T11:01:05.068868Z","iopub.status.idle":"2025-01-10T11:01:05.122032Z","shell.execute_reply.started":"2025-01-10T11:01:05.068836Z","shell.execute_reply":"2025-01-10T11:01:05.121044Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/berlin-amsterdam/raw_data/amsterdam/calendar.csv\n/kaggle/input/berlin-amsterdam/raw_data/amsterdam/listings.csv\n/kaggle/input/berlin-amsterdam/raw_data/amsterdam/neighbourhoods.geojson\n/kaggle/input/berlin-amsterdam/raw_data/amsterdam/reviews.csv\n/kaggle/input/berlin-amsterdam/raw_data/amsterdam/neighbourhoods.csv\n/kaggle/input/berlin-amsterdam/raw_data/amsterdam/summary_information/listings.csv\n/kaggle/input/berlin-amsterdam/raw_data/amsterdam/summary_information/reviews.csv\n/kaggle/input/berlin-amsterdam/raw_data/berlin/calendar.csv\n/kaggle/input/berlin-amsterdam/raw_data/berlin/listings.csv\n/kaggle/input/berlin-amsterdam/raw_data/berlin/neighbourhoods.geojson\n/kaggle/input/berlin-amsterdam/raw_data/berlin/reviews.csv\n/kaggle/input/berlin-amsterdam/raw_data/berlin/neighbourhoods.csv\n/kaggle/input/berlin-amsterdam/raw_data/berlin/summary_information/listings.csv\n/kaggle/input/berlin-amsterdam/raw_data/berlin/summary_information/reviews.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 1 Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom copy import deepcopy\nimport torch \nimport transformers as tf\nfrom torch.utils.data import DataLoader\nimport json\nimport sklearn\nfrom sklearn.decomposition import PCA\nfrom tqdm import tqdm\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.models import ResNet50_Weights\nimport time \n\nDEBUG_MODE = True # determines if preprocessing is in DEBUG_MODE (no processing of file --> execution of main-function)","metadata":{"execution":{"iopub.status.busy":"2025-01-11T21:55:45.504898Z","iopub.execute_input":"2025-01-11T21:55:45.505187Z","iopub.status.idle":"2025-01-11T21:55:52.955092Z","shell.execute_reply.started":"2025-01-11T21:55:45.505162Z","shell.execute_reply":"2025-01-11T21:55:52.954088Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# 2 Dataset-Class Definition","metadata":{}},{"cell_type":"code","source":"class InsideAirbnbDataset:\n    def __init__(\n            self,\n            raw_data_dir: str = \"/kaggle/input/berlin-amsterdam/raw_data\",\n            process_all_cities: bool = True,\n            cities_to_process: list   = [\"berlin\"]):\n        \n        self.process_all_cities = process_all_cities\n        self.cities_to_process = cities_to_process\n\n        self.raw_data_dir = raw_data_dir\n\n        # read in raw data from raw data directory in repository\n        self.raw_data_dict = self._read_data_from_files()\n\n        # integrate the reviews from reviews df into the listings df for each city in the raw_data_dict\n        self._integrate_reviews_into_listings()\n\n        # aggregate all listings dfs from each city and store in one all_cities_listings df\n        self.all_cities_listings = self._aggregate_regional_listings_into_one_df()\n        \n    \n    def _read_data_from_files(self):\n        print(f\"reading in data from {self.raw_data_dir}\")\n        cities_in_raw_data_dir = os.listdir(self.raw_data_dir)\n\n        if not self.process_all_cities and not set(self.cities_to_process).issubset(cities_in_raw_data_dir):\n            raise ValueError(\"not all requested citys are in directory\")\n        \n        raw_data_dict = {}\n\n        if self.process_all_cities:\n            self.cities_to_process = cities_in_raw_data_dir\n\n        self.cities = self.cities_to_process\n        \n        for city in self.cities_to_process:\n            print(f\"collecting data for city: {city}\")\n            raw_data_dict[city] = {}\n            city_dir = self.raw_data_dir + '/' + city\n            file_names = [f for f in os.listdir(city_dir) if os.path.isfile(os.path.join(city_dir, f))]\n\n            for file_name in file_names:\n                if file_name.endswith('.csv') or file_name.endswith('.geojson') or file_name.endswith('.csv.gz'):\n                    file_path = os.path.join(city_dir, file_name)\n            \n                    # Read the file into a DataFrame\n                    if file_name.endswith('.geojson'):\n                        df = pd.read_json(file_path)  # Adjust based on the specific geojson handling\n                    else:\n                        file_name_core = file_name.split(sep=\".\")[0]\n\n                        if file_name_core == \"reviews\":\n                            index_col = 1\n                        else:\n                            index_col = 0\n                            \n                        df = pd.read_csv(file_path, index_col=index_col)\n\n                        # filter out all listings which do not have price available\n                        if file_name_core == \"listings\":\n                            df = df[df[\"price\"].notna()]\n\n                    raw_data_dict[city][file_name] = df\n\n        print(f\"collecting data process done\")\n\n        return raw_data_dict\n\n    def _integrate_reviews_into_listings(self):\n        print(f\"initializing reviews collection process and integration into city listings\")\n        \n        for city in self.cities:\n            print(f\"current city: {city}\")\n            city_listings = self.raw_data_dict[city][\"listings.csv\"]\n            city_reviews = self.raw_data_dict[city][\"reviews.csv\"]       \n            city_calendar = self.raw_data_dict[city][\"calendar.csv\"] \n\n            city_listings_indices = city_listings.index.to_list()\n            city_listings[\"comments\"] = [[] for _ in range(len(city_listings))]\n\n            for index in city_listings_indices:\n                city_index_reviews = city_reviews[city_reviews[\"listing_id\"] == index]\n                comments = city_index_reviews[\"comments\"].to_list()\n\n                comments_with_newline = []\n                for comment in comments:\n                    if type(comment) is float: #if it is nan, as nan are float values\n                        comment = \"\"\n                    comment_transformed = comment.replace('<br/>', '\\n').replace('\\r', '')\n                    comments_with_newline.append(comment_transformed)\n\n                city_listings.at[index, 'comments'] = comments_with_newline\n        \n        print(\"integration of reviews into cites listings done\")\n\n    def _aggregate_regional_listings_into_one_df(self):\n        print(\"initializing aggregation of regional listings into one dataframe\")\n        all_cities_listings = []\n\n        for city in self.cities:\n            city_listings = self.raw_data_dict[city][\"listings.csv\"]\n            city_listings.insert(0, 'region', city)\n            all_cities_listings.append(city_listings)\n\n        all_cities_listings = pd.concat(all_cities_listings, ignore_index=True)\n        print(\"aggregation done\")\n        return all_cities_listings\n\n    def add_nlp_embedding(self, \n                          nlp_col_names = ['name', 'description', 'neighborhood_overview', 'host_about', 'amenities','comments'], \n                          batch_size = 32):\n        print(\"initializing NLP embedding process\")\n        print(f\"batch size: {batch_size}\") \n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        model_name = 'distilbert-base-multilingual-cased'\n        tokenizer = tf.AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n        model = tf.AutoModel.from_pretrained(model_name).to(device)\n        print(f\"embeddings are computed using transformer model: {model_name} from hugging face\")\n        \n        for nlp_col_name in nlp_col_names:\n            print(f\"current nlp column: {nlp_col_name}\")\n\n            nlp_col = self.all_cities_listings[nlp_col_name]\n            nlp_col_list = []\n\n            # convert nlp columns to a list \n            if nlp_col_name in ['name', 'description', 'neighborhood_overview', 'host_about', 'comments']:\n                nlp_col_list = nlp_col.fillna(value=\"\").to_list()\n            elif nlp_col_name == \"amenities\":\n                for amenities_raw_entry in nlp_col:\n                    amenities_collection = json.loads(amenities_raw_entry) # amenities_raw_entry is in json string format\n                    nlp_col_list.append(amenities_collection)\n            else:\n                raise ValueError(f\"no procedure found for converting {nlp_col_name} to list\")\n            \n\n            nlp_col_list_embedded = []\n\n            pooling_approach = ['amenities', 'comments']\n            # for each entry in nlp column, single embeddings are inferred for amenity_items / single reviews --> then mean pooling\n            if nlp_col_name in pooling_approach:\n                for i, entry in enumerate(tqdm(nlp_col_list)):\n                    if entry == []:\n                        entry = np.asarray([\" \"])\n                        \n                    dataloader = DataLoader(entry, batch_size=batch_size)\n                    entry_items_embeddings_list = []\n                    \n                    for batch in dataloader:\n                        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n                        with torch.no_grad():\n                            outputs = model(**inputs)\n                        embeddings = outputs.last_hidden_state[:, 0, :]\n                        embeddings = embeddings.squeeze(0).cpu().numpy()\n                        entry_items_embeddings_list.append(embeddings)\n                    \n                    embeddings_array = np.vstack(entry_items_embeddings_list)\n                    mean_pooled_embedding = np.mean(embeddings_array, axis=0)\n                    nlp_col_list_embedded.append(mean_pooled_embedding)\n                    \n            # embeddings are inferred directly for the entries of all other nlp columns\n            else:\n                dataloader = DataLoader(nlp_col_list, batch_size=batch_size)\n                elements = 0\n                for batch in tqdm(dataloader):\n                    elements += len(batch)\n                    inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n                    with torch.no_grad():\n                        outputs = model(**inputs)\n                    embeddings = outputs.last_hidden_state[:, 0, :]\n                    embeddings = embeddings.cpu().numpy()\n                    if len(list(embeddings)) != len(batch):\n                        print(embeddings.shape)\n                    nlp_col_list_embedded += list(embeddings)\n            \n            nlp_col_embedded_name = nlp_col_name + '_emb'\n            self.all_cities_listings[nlp_col_embedded_name] = nlp_col_list_embedded\n        \n        print(\"nlp embedding done\")\n    \n    def dimensionality_reduction(self, \n                                 col_names = [\n                                    'name_emb', \n                                    'description_emb', \n                                    'neighborhood_overview_emb', \n                                    'host_about_emb', \n                                    'amenities_emb',\n                                    'comments_emb',\n                                    'host_picture_emb',\n                                    'picture_emb'\n                                 ],\n                                keep_variance = 0.95):\n        \n        print(\"initializing dimensionality reduction\")\n            \n        for col_name in col_names:\n            print(f\"current embeddings: {col_name}\")\n            col = self.all_cities_listings[col_name]\n            col_array = np.asarray([np.asarray(entry) for entry in col])\n\n            pca = PCA(n_components = keep_variance, svd_solver='full')\n            pca.fit(col_array)\n            dim_red_col_array = pca.transform(col_array)\n            print(f\"used {pca.n_components_ } components for dim reduction to explain {keep_variance*100}% of the data\")\n            \n            dim_red_col_name = col_name + '_dim_red'\n            self.all_cities_listings[dim_red_col_name] = list(dim_red_col_array)\n        print(\"dimensionality reduction done\")\n\n    def download_images_and_save(self, \n                            image_url_col_names = ['host_picture_url','picture_url'], \n                            saving_dir = 'kaggle/working/preprocessed_data/filtered_dataset_images',\n                            process_n_images = -1):\n        \n        print(\"initializing image embedding process\")\n        for city in self.cities:\n            for image_url_col_name in image_url_col_names:\n                print(f\"downloading images from web for column '{image_url_col_name}'\")\n\n                city_listings = self.all_cities_listings[self.all_cities_listings[\"region\"] == city]\n                image_url_col = city_listings[image_url_col_name]\n                image_list = []\n                no_access_indices = []\n                image_size = (256,256)\n                \n                for i, image_url in enumerate(tqdm(image_url_col)):\n                    if process_n_images >= 0 and i == process_n_images:\n                        break\n                    response = requests.get(image_url)\n                    \n                    # NaN values are floats\n                    if type(image_url) is float:\n                        no_access_indices.append(i)\n                        image_list.append(Image.new(\"RGB\", image_size))\n                    else:\n                        response = requests.get(image_url)\n                        # code for successful request is 200\n                        if response.status_code == 200:\n                            try:\n                                image = Image.open(BytesIO(response.content)).resize(image_size)\n                                if image.mode != \"RGB\":\n                                    image = image.convert('RGB')\n                                image_list.append(image)\n                            except OSError as e:\n                                no_access_indices.append(i)\n                                image_list.append(Image.new(\"RGB\", image_size))  \n                        else:\n                            no_access_indices.append(i)\n                            image_list.append(Image.new(\"RGB\", image_size))\n                            #response.raise_for_status()\n        \n                print(f\"pictures from rows {no_access_indices} could not be accessed\")\n\n                image_saving_path = saving_dir + '/' + city + '/' + image_url_col_name\n                if not os.path.exists(image_saving_path):\n                    os.makedirs(image_saving_path)\n                for i, image in enumerate(image_list):\n                    image.save(image_saving_path + '/' + f\"image_{i}.jpg\")\n                \n            \n\n    def add_image_embedding(self, \n                            image_url_col_names = ['host_picture_url','picture_url'], \n                            batch_size = 32,\n                            read_from_dir = False,\n                            read_dir = 'kaggle/working/preprocessed_data/filtered_dataset_images',\n                            embedd_n_images = -1):\n        \n        print(\"initializing image embedding process\")\n        \n        for image_url_col_name in image_url_col_names:\n            \n            if read_from_dir:\n                print(f\"reading images from directory for column '{image_url_col_name}'\")\n                \n                cities_subdirectories = [d for d in os.listdir(read_dir) if os.path.isdir(os.path.join(read_dir, d))]\n\n                if not set(set(self.cities)).issubset(cities_subdirectories):\n                    raise ValueError(\"not all cities in need to be processed are in given read directory\")\n\n                for city in self.cities:\n                    column_city_subdirectory = read_dir + '/' + city + '/' + image_url_col_name\n                    assert os.path.exists(column_city_subdirectory), f\"subdirectory {column_city_subdirectory} does not exist\"\n                    image_files = os.listdir(column_city_subdirectory)\n                    assert len(image_files) == len(self.all_cities_listings)\n\n                    image_list = []\n                    for image_file in image_files:\n                        image = Image.open(os.path.join(column_city_subdirectory, image_file))\n                        image_list.append(image)\n\n                    assert len(image_list) == len(self.all_cities_listings)\n                    \n            else:\n                print(f\"downloading images from web for column '{image_url_col_name}'\")\n                image_url_col = self.all_cities_listings[image_url_col_name]\n                image_list = []\n                no_access_indices = []\n                image_size = (256,256)\n                \n                for i, image_url in enumerate(tqdm(image_url_col)):\n                    if embedd_n_images >= 0 and i == embedd_n_images:\n                        break\n                    response = requests.get(image_url)\n                    \n                    # NaN values are floats\n                    if type(image_url) is float:\n                        no_access_indices.append(i)\n                        image_list.append(Image.new(\"RGB\", image_size))\n                    else:\n                        response = requests.get(image_url)\n                        # code for successful request is 200\n                        if response.status_code == 200:\n                            try:\n                                image = Image.open(BytesIO(response.content)).resize(image_size)\n                                if image.mode != \"RGB\":\n                                    image = image.convert('RGB')\n                                image_list.append(image)\n                            except OSError as e:\n                                no_access_indices.append(i)\n                                image_list.append(Image.new(\"RGB\", image_size))  \n                        else:\n                            no_access_indices.append(i)\n                            image_list.append(Image.new(\"RGB\", image_size))\n                            #response.raise_for_status()\n        \n                print(f\"pictures from rows {no_access_indices} could not be accessed\")\n            print(\"transform images and construct dataloader\")\n    \n            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n            \n            image_transform = transforms.Compose([\n                                            transforms.Resize(256),\n                                            transforms.CenterCrop(224),\n                                            transforms.ToTensor(),\n                                            normalize\n                                            ])\n            tensor_image_list = [image_transform(image) for image in image_list]\n    \n            data_loader = DataLoader(tensor_image_list, batch_size=batch_size)\n            \n            resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n            modules = list(resnet.children())[:-1]  # remove the FC layer\n            resnet_feature_extractor = torch.nn.Sequential(*modules)\n            resnet_feature_extractor.eval()\n            \n            print(\"embedding image data using ResNet50\")\n            feature_embeddings_list = []\n       \n            for batch in tqdm(data_loader):\n                with torch.no_grad():\n                    feature_embeddings = resnet_feature_extractor(batch)\n                feature_embeddings = feature_embeddings.view(feature_embeddings.size(0), -1).numpy()\n    \n                feature_embeddings_list += list(feature_embeddings)\n    \n            col_name_core = image_url_col_name.split('_')[:-1]\n            image_col_embedded_name = '_'.join(col_name_core + ['emb'])\n            \n            # only important if embedd_n_images not -1 --> not all images get embedded\n            feature_embeddings_list_n = len(feature_embeddings_list)\n            all_listings_n = len(self.all_cities_listings)\n            diff = all_listings_n - feature_embeddings_list_n\n            for _ in range (diff):\n                feature_embeddings_list.append([]) \n                \n    \n            valid_feature_embeddings_list = deepcopy(feature_embeddings_list)[:feature_embeddings_list_n]\n            for index in no_access_indices[::-1]:\n                del valid_feature_embeddings_list[index]\n    \n            valid_feature_embeddings_array = np.asarray(valid_feature_embeddings_list)\n            mean_embedding = np.mean(valid_feature_embeddings_array, axis=0)\n            print(f\"mean_embedding: {mean_embedding}\")\n            \n            for no_access_index in no_access_indices:\n                feature_embeddings_list[no_access_index] = mean_embedding\n    \n            self.all_cities_listings[image_col_embedded_name] = feature_embeddings_list\n            \n        print(\"image embedding done\")\n    \n    def save_all_cities_listings_to_file(self, \n                                         file_name_core, \n                                         saving_dir =  'kaggle/working/preprocessed_data',\n                                         single_data_frames = False):\n        \n        self.saving_dir = saving_dir\n        file_path = saving_dir + '/' + file_name_core + '.csv'\n\n        if single_data_frames:\n            for region in self.all_cities_listings[\"region\"].unique():\n                regional_listing = self.all_cities_listings[self.all_cities_listings[\"region\"] == region]\n                file_path = saving_dir + '/' + file_name_core + f\"_{region}\" + '.csv'\n                regional_listing.to_csv(file_path)\n        else:\n            file_path = saving_dir + '/' + file_name_core + '.csv'\n            self.all_cities_listings.to_csv(file_path)\n        print(f\"all cities listings saved to path: {file_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-11T23:16:53.094351Z","iopub.execute_input":"2025-01-11T23:16:53.094756Z","iopub.status.idle":"2025-01-11T23:16:53.745416Z","shell.execute_reply.started":"2025-01-11T23:16:53.094717Z","shell.execute_reply":"2025-01-11T23:16:53.744164Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# 3 Data Preprocessing\n## 3.1 Reading Data","metadata":{}},{"cell_type":"code","source":"start = time.time()\ndata_set = InsideAirbnbDataset(raw_data_dir=\"/kaggle/input/berlin-amsterdam/raw_data\", process_all_cities= False)","metadata":{"execution":{"iopub.status.busy":"2025-01-11T23:16:58.927734Z","iopub.execute_input":"2025-01-11T23:16:58.92808Z","iopub.status.idle":"2025-01-11T23:17:12.964864Z","shell.execute_reply.started":"2025-01-11T23:16:58.928054Z","shell.execute_reply":"2025-01-11T23:17:12.96381Z"},"trusted":true},"outputs":[{"name":"stdout","text":"reading in data from /kaggle/input/berlin-amsterdam/raw_data\ncollecting data for city: berlin\ncollecting data process done\ninitializing reviews collection process and integration into city listings\ncurrent city: berlin\nintegration of reviews into cites listings done\ninitializing aggregation of regional listings into one dataframe\naggregation done\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#print(data_set.all_cities_listings['accommodates'])\n#print(data_set.all_cities_listings.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T21:13:34.593826Z","iopub.execute_input":"2025-01-09T21:13:34.594202Z","iopub.status.idle":"2025-01-09T21:13:34.598044Z","shell.execute_reply.started":"2025-01-09T21:13:34.59417Z","shell.execute_reply":"2025-01-09T21:13:34.597157Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## 3.2 NLP Embedding","metadata":{}},{"cell_type":"code","source":"data_set.add_nlp_embedding()","metadata":{"execution":{"iopub.status.busy":"2025-01-09T19:10:05.188546Z","iopub.execute_input":"2025-01-09T19:10:05.188894Z","iopub.status.idle":"2025-01-09T19:10:29.084209Z","shell.execute_reply.started":"2025-01-09T19:10:05.188865Z","shell.execute_reply":"2025-01-09T19:10:29.083083Z"},"trusted":true},"outputs":[{"name":"stdout","text":"initializing NLP embedding process\nbatch size: 32\nembeddings are computed using transformer model: distilbert-base-multilingual-cased from hugging face\ncurrent nlp column: name\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 439/439 [00:05<00:00, 77.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"current nlp column: description\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 207/439 [00:17<00:19, 11.81it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-2073ee1a4912>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nlp_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-bd57db031b6a>\u001b[0m in \u001b[0;36madd_nlp_embedding\u001b[0;34m(self, nlp_col_names, batch_size)\u001b[0m\n\u001b[1;32m    166\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9},{"cell_type":"markdown","source":"## 3.3 Image Embedding","metadata":{}},{"cell_type":"code","source":"data_set.download_images_and_save(\n                            image_url_col_names = ['host_picture_url'], \n                            saving_dir = '/kaggle/working',\n                            process_n_images = -1)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-11T21:59:31.777155Z","iopub.execute_input":"2025-01-11T21:59:31.777537Z","iopub.status.idle":"2025-01-11T22:45:53.287875Z","shell.execute_reply.started":"2025-01-11T21:59:31.777506Z","shell.execute_reply":"2025-01-11T22:45:53.286472Z"},"trusted":true},"outputs":[{"name":"stdout","text":"initializing image embedding process\ndownloading images from web for column 'host_picture_url'\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 6757/9008 [38:48<06:45,  5.55it/s]   /usr/local/lib/python3.10/dist-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n100%|██████████| 9008/9008 [46:16<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"pictures from rows [77, 678, 2676, 2677, 2884, 2937, 2948, 2952, 3035, 3255, 3263, 3284, 3340, 3341, 3548, 3642, 3645, 3646, 3647, 3649, 3650, 3651, 3652, 3653, 3657, 4105, 4382, 5989, 6023, 6027, 6034, 6035, 6051, 6053, 6061, 6063, 6065, 6079, 6098, 6099, 6101, 6102, 6133, 6791, 7445, 8402, 8669, 8940, 8942, 8943] could not be accessed\ninitializing image embedding process\ndownloading images from web for column 'host_picture_url'\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-fa631a9788c7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0msaving_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/working'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             process_n_images = -1)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_col_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'host_picture_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_from_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#image_url_col_names = ['host_picture_url']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-78e9a1f28bf9>\u001b[0m in \u001b[0;36madd_image_embedding\u001b[0;34m(self, image_url_col_names, batch_size, read_from_dir, read_dir, embedd_n_images)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"downloading images from web for column '{image_url_col_name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread_from_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0mcities_subdirectories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcities_subdirectories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/nilsk/Dokumente/Machine Learning (MSc.)/1. Semester/Data Literacy/DataLit-InsideAirbnb/data/preprocessed_data/filtered_dataset_images'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'C:/Users/nilsk/Dokumente/Machine Learning (MSc.)/1. Semester/Data Literacy/DataLit-InsideAirbnb/data/preprocessed_data/filtered_dataset_images'","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"data_set.add_image_embedding(image_url_col_names = ['host_picture_url'], read_from_dir = True, read_dir = '/kaggle/working')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T23:17:22.258679Z","iopub.execute_input":"2025-01-11T23:17:22.259046Z","iopub.status.idle":"2025-01-11T23:17:27.171529Z","shell.execute_reply.started":"2025-01-11T23:17:22.259014Z","shell.execute_reply":"2025-01-11T23:17:27.169922Z"}},"outputs":[{"name":"stdout","text":"initializing image embedding process\nreading images from directory for column 'host_picture_url'\ntransform images and construct dataloader\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0d0f9d85c045>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_col_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'host_picture_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_from_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/working'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-5e62733b4e81>\u001b[0m in \u001b[0;36madd_image_embedding\u001b[0;34m(self, image_url_col_names, batch_size, read_from_dir, read_dir, embedd_n_images)\u001b[0m\n\u001b[1;32m    338\u001b[0m                                             \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                                             ])\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mtensor_image_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_image_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-5e62733b4e81>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    338\u001b[0m                                             \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                                             ])\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mtensor_image_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_image_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_num_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":17},{"cell_type":"markdown","source":"## 3.4 Dimensionality Reduction","metadata":{}},{"cell_type":"code","source":"data_set.dimensionality_reduction()","metadata":{"execution":{"iopub.status.busy":"2025-01-09T19:05:10.691176Z","iopub.status.idle":"2025-01-09T19:05:10.691442Z","shell.execute_reply":"2025-01-09T19:05:10.691338Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.5 File Saving","metadata":{}},{"cell_type":"code","source":"data_set.save_all_cities_listings_to_file('integrated_reviews_and_nlp_image_embedding_regional_listing.csv', saving_dir=\"/kaggle/working/filtered_dataset_images\", single_data_frames =True)\ndata_set.download_images_and_save(image_url_col_names = ['host_picture_url'], saving_dir = \"/kaggle/working/filtered_dataset_images\", process_n_images = 10)\n        \ntotal_time = time.time() - start\nprint(f\"script took {total_time} to run\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T21:58:20.694681Z","iopub.execute_input":"2025-01-11T21:58:20.695049Z","iopub.status.idle":"2025-01-11T21:58:20.838883Z","shell.execute_reply.started":"2025-01-11T21:58:20.695023Z","shell.execute_reply":"2025-01-11T21:58:20.837263Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-1aaa52cb3735>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_all_cities_listings_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'integrated_reviews_and_nlp_image_embedding_regional_listing.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/filtered_dataset_images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_data_frames\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_images_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_col_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'host_picture_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/working/filtered_dataset_images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_n_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"script took {total_time} to run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-78e9a1f28bf9>\u001b[0m in \u001b[0;36msave_all_cities_listings_to_file\u001b[0;34m(self, file_name_core, saving_dir, single_data_frames)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mregional_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_cities_listings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_cities_listings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"region\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name_core\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"_{region}\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mregional_listing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name_core\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3900\u001b[0m         )\n\u001b[1;32m   3901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3902\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3903\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         )\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/kaggle/working/filtered_dataset_images'"],"ename":"OSError","evalue":"Cannot save file into a non-existent directory: '/kaggle/working/filtered_dataset_images'","output_type":"error"}],"execution_count":4},{"cell_type":"markdown","source":"## 3.6 Columns Analysis (Uniques & NaNs)","metadata":{}},{"cell_type":"code","source":"numerical_columns = ['host_since', 'host_response_rate', 'host_acceptance_rate', 'host_listings_count', 'host_total_listings_count', 'latitude', 'longitude', \n                     'bathrooms', 'bedrooms', 'beds',\n                     'accommodates', 'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights','maximum_minimum_nights', 'minimum_maximum_nights',\n                     'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'availability_30', 'availability_60', 'availability_90',\n                     'availability_365', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review', 'last_review', 'review_scores_rating', \n                     'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', \n                     'reviews_per_month', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', \n                     'calculated_host_listings_count_shared_rooms']\ncategorical_columns = ['region', 'host_location', 'host_response_time', 'host_is_superhost', 'host_neighbourhood', 'host_has_profile_pic', 'host_identity_verified', \n                       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'property_type', 'room_type', 'has_availability', 'instant_bookable'] #make list with unique values of each column here\nnatural_language_columns = ['name', 'description', 'neighborhood_overview', 'host_about', 'amenities', 'comments']\nimage_weblinks_columns = ['picture_url', 'host_picture_url']\nmeta_data_columns = ['listing_url', 'scrape_id', 'last_scraped', 'source',  'host_id', 'host_url', 'host_name', 'host_thumbnail_url', 'host_verifications', 'neighbourhood', 'calendar_last_scraped', 'license']\nnan_columns = ['calendar_updated']\n\n# not shure: host_name, difference between 'host_listings_count', 'host_total_listings_count', host_verifications\n#how to encode?: host_since as calendar information, host_neigbourhood , 'latitude' and 'longitude'; 'license' as has_license (boolean)?\n# even include? 'neighbourhood' if we have 'region' as part of df but 'neighbourhood_cleansed', 'neighbourhood_group_cleansed' are more exact; 'bathrooms_text' if bathroom is the same\n\n\n#which category?: 'bathrooms'\nall_listings = data_set.all_cities_listings\nprint(all_listings.columns)\n\ncategorical_uniques_n = {cat_col: len(all_listings[cat_col].unique()) for cat_col in categorical_columns}\ncategorical_uniques = {cat_col: all_listings[cat_col].unique() for cat_col in categorical_columns}\n\nnumerical_uniques_n = {num_col: len(all_listings[num_col].unique()) for num_col in numerical_columns}\nnumerical_uniques = {num_col: all_listings[num_col].unique() for num_col in numerical_columns}\n\nmeta_data_uniques_n = {meta_col: len(all_listings[meta_col].unique()) for meta_col in meta_data_columns}\nmeta_data_uniques = {meta_col: all_listings[meta_col].unique() for meta_col in meta_data_columns}\n\n\nprint(meta_data_uniques[\"neighbourhood\"])\n#print(numerical_uniques_n['host_has_profile_pic'])\n","metadata":{"execution":{"iopub.status.busy":"2025-01-10T15:11:51.589839Z","iopub.execute_input":"2025-01-10T15:11:51.590147Z","iopub.status.idle":"2025-01-10T15:11:51.642297Z","shell.execute_reply.started":"2025-01-10T15:11:51.590123Z","shell.execute_reply":"2025-01-10T15:11:51.641331Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Index(['region', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n       'host_neighbourhood', 'host_listings_count',\n       'host_total_listings_count', 'host_verifications',\n       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n       'maximum_minimum_nights', 'minimum_maximum_nights',\n       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n       'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n       'availability_30', 'availability_60', 'availability_90',\n       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review',\n       'last_review', 'review_scores_rating', 'review_scores_accuracy',\n       'review_scores_cleanliness', 'review_scores_checkin',\n       'review_scores_communication', 'review_scores_location',\n       'review_scores_value', 'license', 'instant_bookable',\n       'calculated_host_listings_count',\n       'calculated_host_listings_count_entire_homes',\n       'calculated_host_listings_count_private_rooms',\n       'calculated_host_listings_count_shared_rooms', 'reviews_per_month',\n       'comments'],\n      dtype='object')\n['Berlin, Germany' nan 'Berlin Charlottenburg, Berlin, Germany'\n 'Berlin-Mitte, Berlin, Germany' 'Berlin, Mitte, Germany'\n 'Berlin, Mitte, Berlin, Germany' 'Berlin - Mitte, Germany'\n 'Berlin- Charlottenburg, Berlin, Germany'\n 'Berlin, Kreuzberg, Berlin, Germany' 'Berlin, schmargendorf, Germany'\n 'Berlin, Deutschland, Germany' 'Berlin-Wilmersdorf, Berlin, Germany'\n 'Berlin-Kreuzberg, Berlin, Germany' 'Berlin, Zehlendorf, Germany'\n 'Weissenhoher Strasse 14, Berlin, Germany' 'Berlin, DE, Germany'\n 'Berlin, Be, Germany' 'Berlin-Bohnsdorf, Germany'\n 'Mitte, Berlin, Germany' 'Schöneiche bei Berlin, Brandenburg, Germany'\n 'Alt Treptow, Berlin, Germany' 'Berlin, Prenzlauer Berg, Germany'\n 'Friedrichshain, Berlin, Germany'\n 'Berlin, Prenzlauer Berg, Berlin, Germany']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#nan\nn = len(all_listings)\ncategorical_uniques_percent = {cat_col: len(all_listings[cat_col][all_listings[cat_col].isna()])/n for cat_col in categorical_columns}\nnumerical_uniques_percent = {num_col: len(all_listings[num_col][all_listings[num_col].isna()])/n for num_col in numerical_columns}\nnatural_language_uniques_percent = {nlp_col: len(all_listings[nlp_col][all_listings[nlp_col].isna()])/n for nlp_col in natural_language_columns}\nmeta_uniques_percent = {meta_col: len(all_listings[meta_col][all_listings[meta_col].isna()])/n for meta_col in meta_data_columns}\n\nthreshold = 0.\ncategorical_uniques_percent_threshold ={cat_col: round(percent, 3) for cat_col, percent in categorical_uniques_percent.items() if percent > threshold}\nnumerical_uniques_percent_threshold ={num_col: round(percent, 3) for num_col, percent in numerical_uniques_percent.items() if percent > threshold}\nnatural_language_uniques_percent_threshold ={nlp_col: round(percent, 3) for nlp_col, percent in natural_language_uniques_percent.items() if percent > threshold}\nmeta_uniques_percent_threshold ={meta_col: round(percent, 3) for meta_col, percent in meta_uniques_percent.items() if percent > threshold}\n\"\"\"\nprint(f\"categorical: {categorical_uniques_percent_threshold}\\n\")\nprint(f\"numerical: {numerical_uniques_percent_threshold}\\n\")\nprint(f\"natural_language: {natural_language_uniques_percent_threshold}\\n\")\nprint(f\"meta: {meta_uniques_percent_threshold}\\n\")\n\"\"\"\n\n#categorical NaN:\n#  'host_location'      --> extra NaN category\n#  'host_response_time' --> extra NaN category\n#  'host_is_superhost'  --> False\n#  'host_neighbourhood' --> leave out category     (one unified host neighbourhood with categories should be constructed as other neighbourhood )\n#  'has_availability'   --> False\n\n#numerical NaN:\n#  'host_response_rate'    --> mean/median\n#  'host_acceptance_rate'  --> mean/median\n#  'bathrooms'        --> mean/median\n#  'bedrooms'         --> mean/median\n#  'first_review'     --> leave out category (only include listings which include reviews which indicates that listings are booked and price is valid)\n#   .....\n#  'reviews_per_mon'  --> leave out category (only include listings which include reviews which indicates that listings are booked and price is valid)\n\n#NLP emb\n#  'description'            --> embedding of empty string \" \"\n#  'neighborhood_overview'  --> embedding of empty string \" \"\n#  'host_about'             --> embedding of empty string \" \"\n\n\n# neighbourhood topic:\n#    neighborhood_overview: description of the neighbourhood\n#    host_neighbourhood: where host is located --> meta data\n#    neighbourhood: where listing is located but messy and not consistent --> meta data\n#    neighbourhood_cleansed: where listing is located in conistent and clean way --> categorical data\n#    neighbourhood_group_cleansed: where listing is located but fewer categories than neighbourhood_cleansed --> categorical data\n\n# Question: neighbourhood_cleansed or neighbourhood_group_cleansed? would prefer neighbourhood_cleansed as more exact locator\n\n\"\"\"\nprint(all_listings[\"neighborhood_overview\"])\n\nprint(all_listings[\"host_neighbourhood\"])\n\nprint(all_listings[\"neighbourhood\"])\n\nprint(all_listings[\"neighbourhood_cleansed\"])\nprint(categorical_uniques[\"neighbourhood_cleansed\"])\n\nprint(all_listings[\"neighbourhood_group_cleansed\"])\nprint(categorical_uniques[\"neighbourhood_group_cleansed\"])\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T15:14:31.120755Z","iopub.execute_input":"2025-01-10T15:14:31.121042Z","iopub.status.idle":"2025-01-10T15:14:31.159175Z","shell.execute_reply.started":"2025-01-10T15:14:31.121022Z","shell.execute_reply":"2025-01-10T15:14:31.158151Z"}},"outputs":[{"name":"stdout","text":"0                         Pankow\n1                         Pankow\n2       Friedrichshain-Kreuzberg\n3                          Mitte\n4                         Pankow\n                  ...           \n9003          Treptow - Köpenick\n9004                    Neukölln\n9005                    Neukölln\n9006          Treptow - Köpenick\n9007          Treptow - Köpenick\nName: neighbourhood_group_cleansed, Length: 9008, dtype: object\n['Pankow' 'Friedrichshain-Kreuzberg' 'Mitte' 'Charlottenburg-Wilm.'\n 'Neukölln' 'Tempelhof - Schöneberg' 'Steglitz - Zehlendorf'\n 'Treptow - Köpenick' 'Spandau' 'Lichtenberg' 'Reinickendorf'\n 'Marzahn - Hellersdorf']\n","output_type":"stream"}],"execution_count":19}]}